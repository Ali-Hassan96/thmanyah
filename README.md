Thmanyah â€“ Data Pipeline & Analytics Platform

This project implements an end-to-end data streaming and analytics pipeline designed to simulate a real-world data engineering system for ingesting, enriching, streaming, caching, and analyzing user engagement events.

The system was built as part of a technical evaluation for a Data Engineer role, with a strong focus on:

Streaming data processing

Data enrichment and aggregation

Real-time analytics

Reliability and clarity of design

Careful documentation of decisions and trade-offs

ðŸŽ¯ Project Goal

The primary goal of this project is to stream newly created user engagement events from PostgreSQL, enrich them with content metadata, and fan them out to multiple destinations that serve different use cases:

Redis for low-latency, real-time access (< 5 seconds)

Analytical storage & reporting (via PostgreSQL + Power BI)

External system simulation (loosely coupled message delivery)

The system is designed to be:

Incremental (processes only new data)

Idempotent and safe to restart

Easy to backfill historical data

Fully containerized and reproducible

ðŸ§± High-Level Architecture
PostgreSQL (Source of Truth)
    â†“
Auto-Seed Service (data generation)
    â†“
Spark Streaming (enrichment & transformation)
    â†“
Multi-Sink Fan-out
    â”œâ”€â”€ Redis (Real-time access & aggregation)
    â”œâ”€â”€ PostgreSQL (Analytical tables)
    â””â”€â”€ External System (message-based output)

ðŸš€ Quick Start
Prerequisites

Docker

Docker Compose

Available ports: 5436, 6379, 8080, 8081

Start the Entire System
docker compose up -d


This command starts:

PostgreSQL database

Redis cache

Spark cluster (master + worker)

Automated background services for seeding, streaming, caching, and analysis

Stop the System
docker compose down

View Logs
docker compose logs -f

ðŸ§  Design Decisions (Why These Choices?)
PostgreSQL as the Source of Truth

Reliable relational storage

Clear schema and constraints

Easy to reason about incremental ingestion

Supports backfill and reprocessing

Spark (Structured Streaming)

Supports exactly-once semantics

Handles streaming and batch (backfill) with the same logic

Easy fan-out to multiple sinks

Widely adopted in production data platforms

Redis for Real-Time Use Cases

Sub-second read/write latency

Ideal for real-time dashboards

Supports time-based aggregations

Enables â€œtop content in last N minutesâ€ queries

Docker Compose

Reproducible environment

Minimal setup effort

Easy evaluation and local testing

ðŸ“Š Services Overview
PostgreSQL Database

Connection

Host: localhost

Port: 5436

Database: postgres

Username: postgres

Password: mysecretpassword

Connection String

postgresql://postgres:mysecretpassword@localhost:5436/postgres


Core Tables

content â€“ Content catalog (metadata)

engagement_events â€“ Raw user interaction events

Analytical Tables (Generated by Spark)

content_engagement_metrics

content_engagement_daily

content_type_analysis

device_analysis

Redis Cache

Purpose

Serve enriched events with minimal latency

Support near real-time aggregations

Connection

Host: localhost

Port: 6379

Key Patterns

event:{id} â€“ Single enriched event

content:{id}:events â€“ Recent events per content

events:{type} â€“ Events by type

stats:* â€“ Aggregated metrics

analysis:* â€“ Cached analytical results

RedisInsight (GUI)

URL: http://localhost:8081

Use redis as the host when connecting from Docker

Spark Web UI

URL: http://localhost:8080

Used to monitor:

Jobs

Executors

Streaming batches

ðŸ”„ Automated Background Services
1. Auto-Seed Service

Continuously generates sample content and engagement events

Simulates real user activity

Runs every 30 seconds

Why?

Makes the system self-contained

Removes dependency on external data sources

Enables immediate testing and evaluation

2. Auto-Stream Engagement Service

This is the core streaming pipeline.

What it does

Reads only new engagement events

Enriches events with content metadata

Applies transformations

Writes enriched data to Redis

Transformations

engagement_seconds = duration_ms / 1000

engagement_pct = engagement_seconds / length_seconds

Handles NULL values safely

Rounds percentages to 2 decimal places

Latency Goal

Redis updates arrive within < 5 seconds

3. Auto-Analyze PostgreSQL Service

Runs Spark batch jobs on existing data

Produces aggregated analytical tables

Designed to be rerunnable and idempotent

Why separate analysis from streaming?

Keeps streaming fast and lightweight

Avoids heavy aggregations in real-time paths

Matches real production architectures

4. Auto-Cache Redis Service

Caches analytical results from PostgreSQL into Redis

Enables fast access to aggregated insights

ðŸ“ˆ Analytics & Reporting (Power BI)

Due to limitations in setting up external analytical platforms (e.g., BigQuery) in a local environment, Power BI was used as the analytics and reporting layer.

Why Power BI?

Fast setup

Strong visualization capabilities

Ideal for validating enriched and aggregated data

Separates data processing from data consumption

Power BI connects directly to the analytical tables generated by Spark and provides dashboards such as:

Engagement by content type

Engagement trends over time

Device-based interaction analysis

The system is designed so that BigQuery or any columnar data warehouse can be added later without changing the pipeline logic.

ðŸ” Backfill & Reprocessing

The pipeline supports historical reprocessing by:

Re-running Spark jobs

Adjusting starting offsets or timestamps

Recomputing aggregates safely

This is critical for:

Bug fixes

Schema changes

New metrics

ðŸ› ï¸ Manual Operations
Run Spark Analysis Manually
docker exec -it spark_master spark-submit \
  --master spark://spark-master:7077 \
  --packages org.postgresql:postgresql:42.7.1 \
  /opt/spark/scripts/postgres_analyze_to_postgres.py

ðŸ“ Project Structure
.
â”œâ”€â”€ compose.yaml
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ seeds/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ auto_seed.py
â”‚   â”œâ”€â”€ auto_cache_to_redis.py
â”‚   â””â”€â”€ auto_stream_engagement_to_redis.py
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ jobs/
â”‚   â””â”€â”€ services/
â””â”€â”€ README.md

ðŸš§ Future Improvements

If additional time were available, the following improvements would be implemented:

CDC with Debezium instead of polling

Kafka as a message backbone

Schema Registry

Advanced Redis windowing strategies

Monitoring & alerting (latency, lag, failures)

Load and stress testing

Secrets management and TLS

âœ… Final Notes

This project prioritizes clarity, correctness, and production-like design over unnecessary complexity.
Every decision was made with scalability, maintainability, and real-world applicability in mind.
